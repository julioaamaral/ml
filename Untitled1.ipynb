{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0  Leitura do .Mat (Annotations_train) de Stanford Car DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat  # this is the SciPy module that loads mat-files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados = sio.loadmat('/home/julio/anaconda3/Cars/devkit/cars_train_annos.mat', struct_as_record=False)\n",
    "categoria = sio.loadmat('/home/julio/anaconda3/Cars/devkit/classe_train_annos.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotations = dados['annotations']\n",
    "classe = categoria['classe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bound Box \n",
    "i = 0  #i = [0,8143]\n",
    "print((annotations[0,i].bbox_x1)[0][0])\n",
    "print((annotations[0,i].bbox_y1)[0][0]) \n",
    "print((annotations[0,i].bbox_x2)[0][0])  \n",
    "print((annotations[0,i].bbox_y2)[0][0])  \n",
    "#Classe do Veículo\n",
    "print(classe[0][i])\n",
    "#Veiculo\n",
    "print((annotations[0,i].fname)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Inicio do Processo de Classificação de Imagens utilizando Wavelets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import pywt \n",
    "import numpy as np \n",
    "from pywt import wavedec\n",
    "import matplotlib.pyplot as plt \n",
    "from numpy import mean, sqrt, square\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 2\n",
    "def resizeAndPad(img, size, padColor=0):\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw: # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "    else: # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = w/h\n",
    "\n",
    "    # compute scaling and pad sizing\n",
    "    if aspect > 1: # horizontal image\n",
    "        new_w = sw\n",
    "        new_h = np.round(new_w/aspect).astype(int)\n",
    "        pad_vert = (sh-new_h)/2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1: # vertical image\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h*aspect).astype(int)\n",
    "        pad_horz = (sw-new_w)/2\n",
    "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else: # square image\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n",
    "        padColor = [padColor]*3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
    "\n",
    "    return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 3\n",
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 4\n",
    "#Decomposicao Wavelet dos Canais RGB\n",
    "\n",
    "#Esta função retorna os canais RGB linearizados\n",
    "def getSignalRGB(path,size): \n",
    "    img = cv2.imread(path)\n",
    "    imagem = resizeAndPad(img, (size,size), padColor=0)\n",
    "    b,g,r = cv2.split(imagem)\n",
    "    r =  np.sort(np.asarray((r/r.max()*1.0).flatten(),dtype='float32'))  \n",
    "    g = np.sort(np.asarray((g/g.max()*1.0).flatten(),dtype='float32'))\n",
    "    b =  np.sort(np.asarray((b/b.max()*1.0).flatten(),dtype='float32'))\n",
    "    return [r,g,b]\n",
    "\n",
    "#Esta função retorna os canais RGB na forma de imagens\n",
    "def getImageRGB(path, size): \n",
    "    img = cv2.imread(path)\n",
    "    imagem = resizeAndPad(img, (size,size), padColor=0)\n",
    "    b,g,r = cv2.split(imagem)\n",
    "    r =  np.asarray((r/r.max()*1.0),dtype='float32')\n",
    "    g = np.asarray((g/g.max()*1.0),dtype='float32')\n",
    "    b =  np.asarray((b/b.max()*1.0),dtype='float32')\n",
    "    rgb = cv2.merge((r,g,b))\n",
    "    return [rgb,r,g,b]\n",
    "\n",
    "def plotImageRGB(rgb,r,g,b,rr,gg,bb):\n",
    "    print(\"\\n Imagem RGB\")\n",
    "    plt.imshow(rgb)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal R\")\n",
    "    plt.imshow(r)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal G\")\n",
    "    plt.imshow(g)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal B\")\n",
    "    plt.imshow(b)\n",
    "    plt.show()\n",
    "    plt.plot(rr)\n",
    "    plt.show()\n",
    "    plt.plot(gg)\n",
    "    plt.show()\n",
    "    plt.plot(bb)\n",
    "    plt.show()\n",
    "       \n",
    "def rms(channel, axis=None):\n",
    "    return sqrt(mean(channel**2, axis=axis))  \n",
    "\n",
    "def dwt1d(sinal,wavelet):\n",
    "    coeffs = pywt.dwt(sinal, wavelet, mode='periodization')\n",
    "    return(coeffs)\n",
    "\n",
    "def dwt2d(sinal,wavelet2d):\n",
    "    coeffs = pywt.dwt2(sinal, wavelet2d)\n",
    "    return(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 5\n",
    "#Decomposicao Wavelet dos Canais HSV\n",
    "\n",
    "def getSignalHSV(path,size): \n",
    "    img = cv2.imread(path)\n",
    "    imagem = resizeAndPad(img, (size,size), padColor=0)\n",
    "    HSV = cv2.cvtColor(imagem, cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(HSV)\n",
    "    H =  np.sort(np.asarray((H/H.max()*1.0).flatten(),dtype='float32'))  \n",
    "    S = np.sort(np.asarray((S/S.max()*1.0).flatten(),dtype='float32'))\n",
    "    V =  np.sort(np.asarray((V/V.max()*1.0).flatten(),dtype='float32'))\n",
    "    return(H,S,V)\n",
    "\n",
    "def getImageHSV(path): \n",
    "    img = cv2.imread(path)\n",
    "    HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(HSV)\n",
    "    HSV_t = cv2.merge((H,S,V))\n",
    "    H =  np.asarray((H/H.max()*1.0),dtype='float32')\n",
    "    S = np.asarray((S/S.max()*1.0),dtype='float32')\n",
    "    V =  np.asarray((V/V.max()*1.0),dtype='float32')\n",
    "    HSV = cv2.merge((H,S,V))\n",
    "    return(HSV,H,S,V)\n",
    "\n",
    "def resize(img, size):\n",
    "    imagem = resizeAndPad(img, (size,size), padColor=0)\n",
    "    return imagem \n",
    "\n",
    "def plotImageHSV(hsv,h,s,v,hh,ss,vv):\n",
    "    print(\"\\n Imagem HSV\")\n",
    "    plt.imshow(hsv)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal H\")\n",
    "    plt.imshow(h)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal S\")\n",
    "    plt.imshow(s)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal V\")\n",
    "    plt.imshow(v)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(hh)\n",
    "    plt.show()\n",
    "    plt.plot(ss)\n",
    "    plt.show()\n",
    "    plt.plot(vv)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Janela 6\n",
    "#Aqui são definidos os arquivos de entrada (imagens) \n",
    "images_path = \"/home/julio/anaconda3/Cars/treino/Untitled Folder/\" #Base de Imagens JPG \n",
    "images = np.sort(list(listdir_nohidden(images_path)))\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Janela 7 \n",
    "#imagens usadas neste ensaio (base de dados Stanford)\n",
    "i = 0 \n",
    "print(\"Iniciando. \\nContador de Carros: \"+str(i))\n",
    "for car in images: \n",
    "    full_path = os.path.join(images_path,car)\n",
    "    print(full_path)\n",
    "    i = i + 1\n",
    "print(\"Total de Carros Encontrados em \" + images_path + str(\"  >> \") + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 8 \n",
    "#Mostra os Coeficientes Wavelets\n",
    "def plotWaveletHSV(cah,cas,cav):\n",
    "    print(\"\\nCoeficientes Wavelets de Aproximação\")\n",
    "    print(\"Coeficientes: cA - Canal H\")\n",
    "    plt.imshow(cah)\n",
    "    plt.show()\n",
    "    print(\"Coeficientes: cA - Canal S\")\n",
    "    plt.imshow(cas)\n",
    "    plt.show()\n",
    "    print(\"Coeficientes: cA - Canal V\")\n",
    "    plt.imshow(cav)\n",
    "    plt.show()\n",
    "    plt.plot(cah)\n",
    "    plt.show()\n",
    "    plt.plot(cas)\n",
    "    plt.show()\n",
    "    plt.plot(cav)\n",
    "    plt.show() \n",
    "    \n",
    "def plotWaveletRGB(car,cag,cab):\n",
    "    print(\"\\nCoeficientes Wavelets de Aproximação\")\n",
    "    print(\"Coeficientes: cA - Canal R\")\n",
    "    plt.imshow(car)\n",
    "    plt.show()\n",
    "    print(\"Coeficientes: cA - Canal G\")\n",
    "    plt.imshow(cag)\n",
    "    plt.show()\n",
    "    print(\"Coeficientes: cA - Canal B\")\n",
    "    plt.imshow(cab)\n",
    "    plt.show()\n",
    "    plt.plot(car)\n",
    "    plt.show()\n",
    "    plt.plot(cag)\n",
    "    plt.show()\n",
    "    plt.plot(cab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Testes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Analise no HSV\n",
    "i = 0 \n",
    "COEFICIENTES = []\n",
    "CLASSES = []\n",
    "ARQUIVOS = []\n",
    "for car in images:\n",
    "    WAVELET = []\n",
    "    CLASSE_CARRO = []\n",
    "    ARQUIVO_CARRO = []    \n",
    "    print(\"Número de Imagens Processadas: \" + str(i+1))\n",
    "    full_path = os.path.join(images_path,car)\n",
    "    print(full_path)\n",
    "    [HSV,H,S,V] = getImageHSV(full_path)\n",
    "    \n",
    "    #crop the car image\n",
    "    x1 = (annotations[0,i].bbox_x1)[0][0]\n",
    "    y1 = (annotations[0,i].bbox_y1)[0][0]\n",
    "    x2 = (annotations[0,i].bbox_x2)[0][0]\n",
    "    y2 = (annotations[0,i].bbox_y2)[0][0] \n",
    "    \n",
    "    #classe do veículo \n",
    "    class_car = classe[0][i]\n",
    "    \n",
    "    #arquivo correspondente ao veiculo na base de dados - ex: xxxxx.jpg\n",
    "    file_car = (annotations[0,i].fname)[0]\n",
    "    \n",
    "    #mostrando imagem original\n",
    "    plt.imshow(HSV)\n",
    "    plt.show()\n",
    "    \n",
    "    #cortando a imagem\n",
    "    imagem = HSV[y1:y2, x1:x2]\n",
    "    plt.imshow(imagem)\n",
    "    plt.show()\n",
    "    \n",
    "    #redimensionando \n",
    "    size= 100\n",
    "    image = resize(imagem, size)\n",
    "    \n",
    "    #mostrando imagem redimensionada\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "    #Obtem os Coeficientes Wavelets \n",
    "    H,S,V = cv2.split(image)\n",
    "    [cA_H,(cH,cV,cD)] = dwt2d(H,'bior1.1')\n",
    "    [cA_S,(cH,cV,cD)] = dwt2d(S,'bior1.1')\n",
    "    [cA_V,(cH,cV,cD)] = dwt2d(V,'bior1.1')\n",
    "   \n",
    "    # Exibe os coeficientes \n",
    "    plotWaveletHSV(cA_H,cA_S,cA_V)\n",
    "    \n",
    "    #Lineariza os coeficientes \n",
    "    cw_h = cA_H.flatten()\n",
    "    cw_s = cA_S.flatten()\n",
    "    cw_v = cA_V.flatten()\n",
    "    \n",
    "    #Mostra os coeficientes linearizados \n",
    "    plt.plot(cw_h)\n",
    "    plt.show()\n",
    "    plt.plot(cw_s)\n",
    "    plt.show()\n",
    "    plt.plot(cw_v)\n",
    "    plt.show()\n",
    "\n",
    "    #Mostra os coeficientes linearizados, ordenados e normalizados\n",
    "    plt.plot(np.sort(np.asarray((cw_h/cw_h.max()*1.0).flatten(),dtype='float32')))\n",
    "    plt.show()\n",
    "    plt.plot(np.sort(np.asarray((cw_s/cw_s.max()*1.0).flatten(),dtype='float32')))\n",
    "    plt.show()\n",
    "    plt.plot(np.sort(np.asarray((cw_v/cw_v.max()*1.0).flatten(),dtype='float32')))\n",
    "    plt.show()\n",
    "\n",
    "    #concatena os coeficientes wavelets \n",
    "    wavelets = np.concatenate((cw_h, cw_s, cw_v), axis=0)\n",
    "    \n",
    "    #mostra os coefiencientes wavelets concatenados\n",
    "    plt.plot(wavelets)\n",
    "    plt.show()\n",
    "    \n",
    "       \n",
    "    #Constroi a lista com os coeficientes - uma representacao do veiculo, a classe e o nome do carro\n",
    "    #carro = [wavelets,class_car,file_car]\n",
    "    WAVELET = [wavelets]\n",
    "    CLASSE_CARRO = [class_car]\n",
    "    ARQUIVO_CARRO = [file_car]\n",
    "    #Insere na Base de Dados que sera usada para treinar a Rede Neural\n",
    "    COEFICIENTES.append(WAVELET)\n",
    "    CLASSES.append(CLASSE_CARRO)\n",
    "    ARQUIVOS.append(ARQUIVO_CARRO)\n",
    "    i = i + 1 \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "entrada = np.array(COEFICIENTES) #20x7500\n",
    "entrada = entrada.reshape(20,7500)\n",
    "print(entrada[:20])\n",
    "entrada[0][0][1500:1700] #Primeiro conjunto de coeficientes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saida = np.array(CLASSES)\n",
    "saida = np_utils.to_categorical(saida, 196)#one hot\n",
    "saida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1)\n",
    "\n",
    "# network and training\n",
    "input_size = 7500\n",
    "NB_EPOCH = 200\n",
    "BATCH_SIZE = 16\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 196\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(input_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=OPTIMIZER,\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(entrada,saida,batch_size=BATCH_SIZE, epochs=NB_EPOCH,verbose=VERBOSE, validation_split=0.2)\n",
    "score = model.evaluate(entrada2, saida2, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
