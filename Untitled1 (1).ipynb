{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import pywt \n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pywt import wavedec\n",
    "from scipy.io import loadmat\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dados = sio.loadmat('/home/julio/anaconda3/Cars/devkit/cars_train_annos.mat', struct_as_record=False)\n",
    "categoria = sio.loadmat('/home/julio/anaconda3/Cars/devkit/classe.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = dados['annotations']\n",
    "classe = categoria['classe'] #8144 classes, uma para cada veículo do conjunto de treino\n",
    "print(\"Classes dos Veiculos \"+str(classe.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bound Box, Classe e Aquivo.jpg (Conjunto de Treino)\n",
    "for i in range(classe.shape[1]): #i esta em [1,8144]\n",
    "    print(\"Imagem : \"+str(i)+\".  Arquivo(\"+annotations[0,i].fname[0]+str(\")\"))\n",
    "    print((annotations[0,i].bbox_x1)[0][0])\n",
    "    print((annotations[0,i].bbox_y1)[0][0])\n",
    "    print((annotations[0,i].bbox_x2)[0][0])\n",
    "    print((annotations[0,i].bbox_y2)[0][0])\n",
    "    #Classe do Veículo\n",
    "    print(\"Classe do Veículo :\"+str(classe[0][i]))\n",
    "    print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#resize images\n",
    "def resizeAndPad(img, size, padColor):\n",
    "    h, w = img.shape[:2]\n",
    "    sh, sw = size\n",
    "\n",
    "    # interpolation method\n",
    "    if h > sh or w > sw: # shrinking image\n",
    "        interp = cv2.INTER_AREA\n",
    "    else: # stretching image\n",
    "        interp = cv2.INTER_CUBIC\n",
    "\n",
    "    # aspect ratio of image\n",
    "    aspect = w/h\n",
    "\n",
    "    # compute scaling and pad sizing\n",
    "    if aspect > 1: # horizontal image\n",
    "        new_w = sw\n",
    "        new_h = np.round(new_w/aspect).astype(int)\n",
    "        pad_vert = (sh-new_h)/2\n",
    "        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)\n",
    "        pad_left, pad_right = 0, 0\n",
    "    elif aspect < 1: # vertical image\n",
    "        new_h = sh\n",
    "        new_w = np.round(new_h*aspect).astype(int)\n",
    "        pad_horz = (sw-new_w)/2\n",
    "        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)\n",
    "        pad_top, pad_bot = 0, 0\n",
    "    else: # square image\n",
    "        new_h, new_w = sh, sw\n",
    "        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0\n",
    "\n",
    "    # set pad color\n",
    "    if len(img.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): # color image but only one color provided\n",
    "        padColor = [padColor]*3\n",
    "\n",
    "    # scale and pad\n",
    "    scaled_img = cv2.resize(img, (new_w, new_h), interpolation=interp)\n",
    "    scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)\n",
    "\n",
    "    return scaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wavelets\n",
    "def dwt1d(sinal,wavelet):\n",
    "    coeffs = pywt.dwt(sinal, wavelet, mode='periodization')\n",
    "    return(coeffs)\n",
    "\n",
    "def dwt2d(sinal,wavelet2d):\n",
    "    coeffs = pywt.dwt2(sinal, wavelet2d, mode='periodization')\n",
    "    return(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 5\n",
    "#Decomposicao Wavelet dos Canais HSV\n",
    "\n",
    "def getSignalHSV(path,size): \n",
    "    img = cv2.imread(path)\n",
    "    imagem = resizeAndPad(img, (size,size), padColor=0)\n",
    "    HSV = cv2.cvtColor(imagem, cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(HSV)\n",
    "    H =  np.sort(np.asarray((H/H.max()*1.0).flatten(),dtype='float32'))  \n",
    "    S = np.sort(np.asarray((S/S.max()*1.0).flatten(),dtype='float32'))\n",
    "    V =  np.sort(np.asarray((V/V.max()*1.0).flatten(),dtype='float32'))\n",
    "    return(H,S,V)\n",
    "\n",
    "def getImageHSV(path): \n",
    "    img = cv2.imread(path)\n",
    "    HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(HSV)\n",
    "    HSV_t = cv2.merge((H,S,V))\n",
    "    H =  np.asarray((H/H.max()*1.0),dtype='float32')\n",
    "    S = np.asarray((S/S.max()*1.0),dtype='float32')\n",
    "    V =  np.asarray((V/V.max()*1.0),dtype='float32')\n",
    "    HSV = cv2.merge((H,S,V))\n",
    "    return(HSV,H,S,V)\n",
    "\n",
    "def resize(img, size,cor):\n",
    "    imagem = resizeAndPad(img, (size,size), cor)\n",
    "    return imagem \n",
    "\n",
    "def plotImageHSV(hsv,h,s,v,hh,ss,vv):\n",
    "    print(\"\\n Imagem HSV\")\n",
    "    plt.imshow(hsv)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal H\")\n",
    "    plt.imshow(h)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal S\")\n",
    "    plt.imshow(s)\n",
    "    plt.show()\n",
    "    print(\"\\n Canal V\")\n",
    "    plt.imshow(v)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(hh)\n",
    "    plt.show()\n",
    "    plt.plot(ss)\n",
    "    plt.show()\n",
    "    plt.plot(vv)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui são definidos os arquivos de entrada (imagens) \n",
    "images_path = \"/home/julio/anaconda3/Cars/treino/cars_train/\" #Base de Imagens JPG \n",
    "images = [f for f in listdir(images_path) if isfile(join(images_path, f))] \n",
    "imagens = np.sort(np.array([images])) \n",
    "print(\"Arquivos Encontrados :\"+str(imagens.size))\n",
    "for i in range(imagens.size):\n",
    "    full_path = images_path+str(imagens[0][i])\n",
    "    print(full_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Janela 8 \n",
    "#Mostra os Coeficientes Wavelets\n",
    "def plotWaveletHSV(cah,cas,cav):\n",
    "    print(\"\\nCoeficientes Wavelets de Aproximação\")\n",
    "    print(\"Coeficientes: cA - Canal H\")\n",
    "    plt.imshow(cah)\n",
    "    plt.show()\n",
    "    print(\"Coeficientes: cA - Canal S\")\n",
    "    plt.imshow(cas)\n",
    "    plt.show()\n",
    "    print(\"Coeficientes: cA - Canal V\")\n",
    "    plt.imshow(cav)\n",
    "    plt.show()\n",
    "    plt.plot(cah)\n",
    "    plt.show()\n",
    "    plt.plot(cas)\n",
    "    plt.show()\n",
    "    plt.plot(cav)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_NET = [] #armazena os coeficientes wavelets resultantes da decomposicao da imagem \n",
    "TARGET_NET = [] # armazena as respectivas classes dos veiculos\n",
    "INPUT_FILES = [] #armazena os nomes dos arquivos\n",
    "for i in range(imagens.size-2):\n",
    "    CARRO_WAVELETS = []\n",
    "    CARRO_CLASSE = []\n",
    "    CARRO_JPG = []\n",
    "    full_path = images_path+str(imagens[0][i])\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"Imagem : \"+str(i)+\" >> \"+full_path)\n",
    "    [HSV,H,S,V] = getImageHSV(full_path)\n",
    "    #COORDENADAS PARA O CORTE DA IMAGEM\n",
    "    x1 = (annotations[0,i].bbox_x1)[0][0]\n",
    "    y1 = (annotations[0,i].bbox_y1)[0][0]\n",
    "    x2 = (annotations[0,i].bbox_x2)[0][0]\n",
    "    y2 = (annotations[0,i].bbox_y2)[0][0] \n",
    "    print(\"X1 :\"+str(x1))\n",
    "    print(\"Y1 :\"+str(y1))\n",
    "    print(\"X2 :\"+str(x2))\n",
    "    print(\"Y2 :\"+str(y2))\n",
    "    \n",
    "    #CLASSE DO VEICULO = 0 A 196  \n",
    "    class_car = classe[0][i]\n",
    "    print(\"Classe do Veiculo :\"+str(class_car))\n",
    "    \n",
    "    #ARQUIVO NO DATASET - STANFORD CAR DATASET - CAR-TRAIN\n",
    "    file_car = (annotations[0,i].fname)[0]\n",
    "    print(\"Arquivo JPG do Veículo :\"+str(file_car))\n",
    "    \n",
    "    #MOSTRA A IMAGEM ORIGINAL \n",
    "    #plt.imshow(HSV)\n",
    "    #plt.show()\n",
    "    \n",
    "    #CORTA A IMAGEM ORIGINAL\n",
    "    IMAGEM_CORTADA = HSV[y1:y2, x1:x2]\n",
    "    #plt.imshow(IMAGEM_CORTADA)\n",
    "    #plt.show()\n",
    "    \n",
    "    #REDIMENSIONA A IMAGEM CORTADA  \n",
    "    tamanho = 200\n",
    "    IMAGEM_CORTADA_REDIMENSIONADA = resize(IMAGEM_CORTADA, tamanho, 0) #0 = preto, 1 = branco\n",
    "    #plt.imshow(IMAGEM_CORTADA_REDIMENSIONADA)\n",
    "    #plt.show()\n",
    "    \n",
    "    #DECOMPOE A IMAGEM EM SEUS CANAIS H,S,V\n",
    "    H,S,V = cv2.split(IMAGEM_CORTADA_REDIMENSIONADA)\n",
    "    #plt.imshow(H)\n",
    "    #plt.show()\n",
    "    #plt.imshow(S)\n",
    "    #plt.show()\n",
    "    #plt.imshow(V)\n",
    "    #plt.show()\n",
    "    \n",
    "    #ARVORE ESQUERDA - DECOMPOSICAO RECURSIVA DO CANAL DE BAIXA FREQUENCIA - cA\n",
    "    #OBTEM OS COEFICIENTES WAVELETS - PRIMEIRO NIVEL DE DECOMPOSICAO\n",
    "    [cA_H,(cH,cV,cD)] = dwt2d(H,'bior1.1')\n",
    "    [cA_S,(cH,cV,cD)] = dwt2d(S,'bior1.1')\n",
    "    [cA_V,(cH,cV,cD)] = dwt2d(V,'bior1.1')\n",
    "    wh = cA_H\n",
    "    ws = cA_S\n",
    "    wv = cA_V\n",
    "    #Exibe os coeficientes da primeira decomposicao \n",
    "    #print(\"Primeira Decomposicao\")\n",
    "    #plotWaveletHSV(wh,ws,wv)\n",
    "    \n",
    "    \n",
    "    #OBTEM OS COEFICIENTES WAVELETS - SSEGUNDO NIVEL DE DECOMPOSICAO\n",
    "    [cA_H2,(cH,cV,cD)] = dwt2d(wh,'bior1.1')\n",
    "    [cA_S2,(cH,cV,cD)] = dwt2d(ws,'bior1.1')\n",
    "    [cA_V2,(cH,cV,cD)] = dwt2d(wv,'bior1.1')\n",
    "    wh2 = cA_H2\n",
    "    ws2 = cA_S2\n",
    "    wv2 = cA_V2\n",
    "    #Exibe os coeficientes da segunda decomposicao  \n",
    "   # print(\"Segunda Decomposicao\")\n",
    "   # plotWaveletHSV(wh2,ws2,wv2)\n",
    "    \n",
    "    \n",
    "    #OBTEM OS COEFICIENTES WAVELETS - TERCEIRO NIVEL DE DECOMPOSICAO\n",
    "    [cA_H3,(cH,cV,cD)] = dwt2d(wh2,'bior1.1')\n",
    "    [cA_S3,(cH,cV,cD)] = dwt2d(ws2,'bior1.1')\n",
    "    [cA_V3,(cH,cV,cD)] = dwt2d(wv2,'bior1.1')\n",
    "    wh3 = cA_H3\n",
    "    ws3 = cA_S3\n",
    "    wv3 = cA_V3\n",
    "    #Exibe os coeficientes da terceira decomposicao \n",
    "   # print(\"Terceira Decomposicao\")\n",
    "   # plotWaveletHSV(wh3,ws3,wv3)\n",
    "    \n",
    "    #OBTEM OS COEFICIENTES WAVELETS - Quarto NIVEL DE DECOMPOSICAO\n",
    "    [cA_H4,(cH,cV,cD)] = dwt2d(wh3,'bior1.1')\n",
    "    [cA_S4,(cH,cV,cD)] = dwt2d(ws3,'bior1.1')\n",
    "    [cA_V4,(cH,cV,cD)] = dwt2d(wv3,'bior1.1')\n",
    "    wh4 = cA_H4\n",
    "    ws4 = cA_S4\n",
    "    wv4 = cA_V4\n",
    "    #Exibe os coeficientes da terceira decomposicao  \n",
    "    #print(\"Quarta Decomposicao\")\n",
    "    #plotWaveletHSV(wh4,ws4,wv4)\n",
    "        \n",
    "    #Lineariza e normaliza os coeficientes \n",
    "    wh = np.asarray((wh/wh.max()*1.0).flatten(),dtype='float32')\n",
    "    ws = np.asarray((ws/ws.max()*1.0).flatten(),dtype='float32')\n",
    "    wv = np.asarray((wv/wv.max()*1.0).flatten(),dtype='float32')\n",
    "    wh2 = np.asarray((wh2/wh2.max()*1.0).flatten(),dtype='float32')\n",
    "    ws2 = np.asarray((ws2/ws2.max()*1.0).flatten(),dtype='float32')\n",
    "    wv2 = np.asarray((wv2/wv2.max()*1.0).flatten(),dtype='float32')\n",
    "    wh3 = np.asarray((wh3/wh3.max()*1.0).flatten(),dtype='float32')\n",
    "    ws3 = np.asarray((ws3/ws3.max()*1.0).flatten(),dtype='float32')\n",
    "    wv3 = np.asarray((wv3/wv3.max()*1.0).flatten(),dtype='float32')\n",
    "    wh4 = np.asarray((wh4/wh4.max()*1.0).flatten(),dtype='float32')\n",
    "    ws4 = np.asarray((ws4/ws4.max()*1.0).flatten(),dtype='float32')\n",
    "    wv4 = np.asarray((wv4/wv4.max()*1.0).flatten(),dtype='float32')\n",
    "    \n",
    "    #print(wh.shape)\n",
    "    #print(wh2.shape)\n",
    "    #print(wh3.shape)\n",
    "    #print(wh4.shape)\n",
    "           \n",
    "    #concatena os coeficientes wavelets \n",
    "    wavelets1 = np.concatenate((wh,ws,wv), axis=0)\n",
    "    wavelets2 = np.concatenate((wh,ws,wv,wh2,ws2,wv2), axis=0)\n",
    "    wavelets3 = np.concatenate((wh,ws,wv,wh2,ws2,wv2,wh3,ws3,wv3), axis=0)\n",
    "    wavelets4 = np.concatenate((wh,ws,wv,wh2,ws2,wv2,wh3,ws3,wv3,wh4,ws4,wv4), axis=0)\n",
    "   # print(wavelets1.shape)\n",
    "   # plt.plot(wavelets1)\n",
    "   # plt.show()\n",
    "   # print(wavelets2.shape)\n",
    "   # plt.plot(wavelets2)\n",
    "   # plt.show()\n",
    "   # print(wavelets3.shape)\n",
    "   # plt.plot(wavelets3)\n",
    "   # plt.show()\n",
    "   # print(wavelets4.shape)\n",
    "    plt.plot(wavelets4)\n",
    "    plt.show()\n",
    "    \n",
    "    CARRO_WAVELETS = [wavelets4]\n",
    "    CARRO_CLASSE = [class_car]\n",
    "    CARRO_JPG = [file_car]\n",
    "    \n",
    "        \n",
    "    INPUT_NET.append(CARRO_WAVELETS)\n",
    "    TARGET_NET.append(CARRO_CLASSE)\n",
    "    INPUT_FILES.append(CARRO_JPG)\n",
    "      \n",
    "       \n",
    "    i = i + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INPUT_NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TARGET_NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INPUT_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1)\n",
    "\n",
    "#ENTRADA DE DADOS\n",
    "INPUT = np.array(INPUT_NET)\n",
    "print(\"Dados de Entrada da Rede :\",INPUT.shape)\n",
    "INPUT = INPUT.reshape(INPUT.shape[0],INPUT.shape[2])\n",
    "print(\"Dados de Entrada da Rede :\",INPUT.shape)\n",
    "\n",
    "#ALVO = SAIDA DESEJADA\n",
    "TARGET = np.array(TARGET_NET)\n",
    "print(\"Saida sem One Hot Encoding\\n \"+str(TARGET))\n",
    "TARGET = np_utils.to_categorical(TARGET, 196) \n",
    "print(\"Saida no Formato One Hot Encoded :\\n \"+str(TARGET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# network and training\n",
    "input_size = INPUT.shape[1]\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 1\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 196 #196\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(input_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,metrics=['accuracy'])\n",
    "history = model.fit(INPUT,TARGET,batch_size=BATCH_SIZE, epochs=NB_EPOCH,verbose=VERBOSE, validation_split=0.2)\n",
    "score = model.evaluate(INPUT, TARGET, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REAL_NET_OUTPUT = model.predict(INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "REDE = 'np.argmax(p, axis=1): {0}'.format(np.argmax(REAL_NET_OUTPUT, axis=1))\n",
    "CORRETA = 'np.argmax(p, axis=1): {0}'.format(np.argmax(TARGET, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CORRETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(REDE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array(history.history['acc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.array(history.history['loss']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
